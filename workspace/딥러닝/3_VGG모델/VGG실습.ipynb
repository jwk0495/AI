{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sequential -> 차례로 쌓아가는 과정\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_classes=1000):   # num_classes=1000 -> 클래스의 수를 1000으로 설정\n",
    "        super(VGG16, self).__init__()       # super -> nn.Module을 가리킴\n",
    "        self.features = nn.Sequential(      # Sequential -> 차례대로 시퀀서를 쌓음\n",
    "            # 첫 번째 블록\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),    # 1층\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),   # 2층\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                                  # 반으로 줄어듬\n",
    "\n",
    "            # 두 번째 블록\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),  # 3층\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1), # 4층\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # 세 번째 블록\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1), # 5층\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1), # 6층\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1), # 7층\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # 네 번째 블록\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1), # 8층\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1), # 9층\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1), # 10층\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # 다섯 번째 블록\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1), # 11층\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1), # 12층\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1), # 13층\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),   # 14층\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "\n",
    "            nn.Linear(4096, 4096),          # 15층\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "\n",
    "            nn.Linear(4096, num_classes),   # 16층\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, size=(224, 224), mode= \"bilinear\", align_corners= False) # Model에 맞는 이미지 사이즈 = 224, 224 사이즈\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)           # 평탄화 과정 -> flatten\n",
    "        x = self.classifier(x)              # 분류\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 생성\n",
    "model = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터셋 준비\n",
    "import torchvision\n",
    "from torchvision import transforms              # == import torchvision.transforms as transforms #\n",
    "from torch import optim                         # == import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 가져오기\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:16<00:00, 10286356.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\cifar-10-python.tar.gz to ../data\n"
     ]
    }
   ],
   "source": [
    "# 전체 train 데이터셋 가져오기 : train : val : test -> 80 : 10 : 10\n",
    "trainset_full = torchvision.datasets.CIFAR10(root=\"../data\", train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: ../data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "           )"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5219,\n",
       " 32326,\n",
       " 43827,\n",
       " 6153,\n",
       " 26640,\n",
       " 421,\n",
       " 31738,\n",
       " 4700,\n",
       " 7021,\n",
       " 26070,\n",
       " 36724,\n",
       " 37185,\n",
       " 17689,\n",
       " 19031,\n",
       " 28867,\n",
       " 1724,\n",
       " 18759,\n",
       " 1173,\n",
       " 20412,\n",
       " 41479,\n",
       " 39224,\n",
       " 24200,\n",
       " 11266,\n",
       " 18373,\n",
       " 7298,\n",
       " 25361,\n",
       " 38009,\n",
       " 15429,\n",
       " 36940,\n",
       " 4651,\n",
       " 38107,\n",
       " 47642,\n",
       " 49818,\n",
       " 27667,\n",
       " 42609,\n",
       " 21611,\n",
       " 33738,\n",
       " 43870,\n",
       " 47606,\n",
       " 9838,\n",
       " 29460,\n",
       " 16507,\n",
       " 4665,\n",
       " 11186,\n",
       " 10210,\n",
       " 39305,\n",
       " 21423,\n",
       " 18870,\n",
       " 39531,\n",
       " 18092,\n",
       " 15668,\n",
       " 5262,\n",
       " 34780,\n",
       " 1570,\n",
       " 21995,\n",
       " 35380,\n",
       " 8819,\n",
       " 43670,\n",
       " 40000,\n",
       " 29075,\n",
       " 11404,\n",
       " 31839,\n",
       " 102,\n",
       " 18494,\n",
       " 15404,\n",
       " 39376,\n",
       " 41878,\n",
       " 24620,\n",
       " 30919,\n",
       " 45932,\n",
       " 12691,\n",
       " 15014,\n",
       " 49387,\n",
       " 16490,\n",
       " 29157,\n",
       " 7697,\n",
       " 39420,\n",
       " 18106,\n",
       " 43657,\n",
       " 25336,\n",
       " 30052,\n",
       " 46220,\n",
       " 30699,\n",
       " 47929,\n",
       " 33936,\n",
       " 17857,\n",
       " 28429,\n",
       " 18699,\n",
       " 41474,\n",
       " 1540,\n",
       " 13979,\n",
       " 32204,\n",
       " 19763,\n",
       " 30292,\n",
       " 7979,\n",
       " 17771,\n",
       " 28195,\n",
       " 36671,\n",
       " 41763,\n",
       " 38498,\n",
       " 9337,\n",
       " 2226,\n",
       " 6258,\n",
       " 43171,\n",
       " 44764,\n",
       " 37053,\n",
       " 23814,\n",
       " 1507,\n",
       " 8227,\n",
       " 46715,\n",
       " 39782,\n",
       " 14066,\n",
       " 4202,\n",
       " 1398,\n",
       " 11614,\n",
       " 2697,\n",
       " 33873,\n",
       " 6243,\n",
       " 7682,\n",
       " 21158,\n",
       " 22433,\n",
       " 33245,\n",
       " 1492,\n",
       " 7607,\n",
       " 6114,\n",
       " 41584,\n",
       " 10674,\n",
       " 46249,\n",
       " 14654,\n",
       " 31515,\n",
       " 3600,\n",
       " 41177,\n",
       " 24134,\n",
       " 21118,\n",
       " 45040,\n",
       " 8050,\n",
       " 19907,\n",
       " 36143,\n",
       " 11016,\n",
       " 44223,\n",
       " 39694,\n",
       " 9018,\n",
       " 13062,\n",
       " 32706,\n",
       " 16747,\n",
       " 30542,\n",
       " 6816,\n",
       " 18470,\n",
       " 22681,\n",
       " 5332,\n",
       " 30362,\n",
       " 28789,\n",
       " 2682,\n",
       " 7118,\n",
       " 6376,\n",
       " 67,\n",
       " 5333,\n",
       " 28225,\n",
       " 43925,\n",
       " 21128,\n",
       " 23557,\n",
       " 36393,\n",
       " 47061,\n",
       " 38685,\n",
       " 23190,\n",
       " 4973,\n",
       " 27721,\n",
       " 5054,\n",
       " 41294,\n",
       " 43895,\n",
       " 11710,\n",
       " 9996,\n",
       " 18223,\n",
       " 26261,\n",
       " 19995,\n",
       " 35487,\n",
       " 32979,\n",
       " 30567,\n",
       " 46236,\n",
       " 10244,\n",
       " 4727,\n",
       " 17422,\n",
       " 10756,\n",
       " 18486,\n",
       " 3948,\n",
       " 7550,\n",
       " 40560,\n",
       " 34197,\n",
       " 21515,\n",
       " 11966,\n",
       " 41368,\n",
       " 28112,\n",
       " 39380,\n",
       " 10310,\n",
       " 8977,\n",
       " 33501,\n",
       " 12475,\n",
       " 7808,\n",
       " 21773,\n",
       " 2247,\n",
       " 17172,\n",
       " 33895,\n",
       " 34124,\n",
       " 18454,\n",
       " 37291,\n",
       " 40645,\n",
       " 16511,\n",
       " 42982,\n",
       " 38912,\n",
       " 43293,\n",
       " 16721,\n",
       " 6490,\n",
       " 10981,\n",
       " 1752,\n",
       " 29980,\n",
       " 17524,\n",
       " 15163,\n",
       " 30058,\n",
       " 39550,\n",
       " 16003,\n",
       " 7725,\n",
       " 47150,\n",
       " 25581,\n",
       " 15227,\n",
       " 23947,\n",
       " 6100,\n",
       " 28911,\n",
       " 16997,\n",
       " 4074,\n",
       " 30672,\n",
       " 24499,\n",
       " 25080,\n",
       " 34082,\n",
       " 2600,\n",
       " 7627,\n",
       " 17343,\n",
       " 4423,\n",
       " 49575,\n",
       " 36149,\n",
       " 7876,\n",
       " 25814,\n",
       " 22280,\n",
       " 24136,\n",
       " 45078,\n",
       " 43486,\n",
       " 49836,\n",
       " 29623,\n",
       " 19712,\n",
       " 17287,\n",
       " 37447,\n",
       " 15706,\n",
       " 41456,\n",
       " 9391,\n",
       " 49644,\n",
       " 18122,\n",
       " 24581,\n",
       " 48643,\n",
       " 49429,\n",
       " 7705,\n",
       " 12723,\n",
       " 20967,\n",
       " 12477,\n",
       " 22950,\n",
       " 10676,\n",
       " 33751,\n",
       " 28019,\n",
       " 10879,\n",
       " 4274,\n",
       " 2791,\n",
       " 22378,\n",
       " 870,\n",
       " 14285,\n",
       " 24885,\n",
       " 18439,\n",
       " 22282,\n",
       " 41255,\n",
       " 30784,\n",
       " 20222,\n",
       " 47556,\n",
       " 14478,\n",
       " 22617,\n",
       " 9196,\n",
       " 20616,\n",
       " 23123,\n",
       " 9863,\n",
       " 28101,\n",
       " 44421,\n",
       " 47727,\n",
       " 41598,\n",
       " 13817,\n",
       " 42236,\n",
       " 47516,\n",
       " 41751,\n",
       " 6381,\n",
       " 6280,\n",
       " 29337,\n",
       " 39996,\n",
       " 38677,\n",
       " 15359,\n",
       " 21061,\n",
       " 36336,\n",
       " 26014,\n",
       " 24444,\n",
       " 3834,\n",
       " 24047,\n",
       " 26410,\n",
       " 32215,\n",
       " 25313,\n",
       " 36004,\n",
       " 2744,\n",
       " 34008,\n",
       " 11242,\n",
       " 1184,\n",
       " 12415,\n",
       " 4168,\n",
       " 1263,\n",
       " 1267,\n",
       " 42747,\n",
       " 47055,\n",
       " 19575,\n",
       " 7054,\n",
       " 1753,\n",
       " 3061,\n",
       " 19250,\n",
       " 1817,\n",
       " 6384,\n",
       " 39078,\n",
       " 470,\n",
       " 34531,\n",
       " 20690,\n",
       " 18356,\n",
       " 17272,\n",
       " 3718,\n",
       " 36535,\n",
       " 17348,\n",
       " 26859,\n",
       " 24422,\n",
       " 9550,\n",
       " 35130,\n",
       " 27915,\n",
       " 42230,\n",
       " 6311,\n",
       " 5562,\n",
       " 39379,\n",
       " 19007,\n",
       " 6053,\n",
       " 37271,\n",
       " 35711,\n",
       " 42845,\n",
       " 45943,\n",
       " 21033,\n",
       " 36767,\n",
       " 3184,\n",
       " 35594,\n",
       " 8746,\n",
       " 45512,\n",
       " 9655,\n",
       " 47546,\n",
       " 17052,\n",
       " 42767,\n",
       " 30102,\n",
       " 25040,\n",
       " 36258,\n",
       " 3985,\n",
       " 25628,\n",
       " 49897,\n",
       " 16051,\n",
       " 22804,\n",
       " 4181,\n",
       " 23672,\n",
       " 7177,\n",
       " 43497,\n",
       " 44731,\n",
       " 44211,\n",
       " 13099,\n",
       " 17969,\n",
       " 24549,\n",
       " 45453,\n",
       " 18618,\n",
       " 453,\n",
       " 28655,\n",
       " 26754,\n",
       " 22685,\n",
       " 37126,\n",
       " 5723,\n",
       " 49853,\n",
       " 37559,\n",
       " 39271,\n",
       " 35842,\n",
       " 45357,\n",
       " 12920,\n",
       " 42547,\n",
       " 17455,\n",
       " 32774,\n",
       " 35221,\n",
       " 23846,\n",
       " 34894,\n",
       " 14960,\n",
       " 40485,\n",
       " 46471,\n",
       " 33019,\n",
       " 33916,\n",
       " 12634,\n",
       " 20396,\n",
       " 21955,\n",
       " 14653,\n",
       " 48135,\n",
       " 43517,\n",
       " 49005,\n",
       " 15347,\n",
       " 7155,\n",
       " 45676,\n",
       " 45490,\n",
       " 23225,\n",
       " 5508,\n",
       " 11526,\n",
       " 14427,\n",
       " 28134,\n",
       " 49833,\n",
       " 21336,\n",
       " 8796,\n",
       " 14073,\n",
       " 21846,\n",
       " 43126,\n",
       " 48819,\n",
       " 49004,\n",
       " 38614,\n",
       " 2199,\n",
       " 5755,\n",
       " 18631,\n",
       " 17164,\n",
       " 30036,\n",
       " 29539,\n",
       " 25753,\n",
       " 3345,\n",
       " 15107,\n",
       " 45700,\n",
       " 7258,\n",
       " 12034,\n",
       " 44809,\n",
       " 6111,\n",
       " 34506,\n",
       " 27476,\n",
       " 34222,\n",
       " 26898,\n",
       " 38901,\n",
       " 27460,\n",
       " 39410,\n",
       " 28702,\n",
       " 35042,\n",
       " 37504,\n",
       " 41937,\n",
       " 38639,\n",
       " 46483,\n",
       " 48009,\n",
       " 15368,\n",
       " 45506,\n",
       " 28796,\n",
       " 16111,\n",
       " 30581,\n",
       " 38818,\n",
       " 47017,\n",
       " 25455,\n",
       " 33592,\n",
       " 12316,\n",
       " 22083,\n",
       " 4437,\n",
       " 45186,\n",
       " 39489,\n",
       " 48789,\n",
       " 41105,\n",
       " 34520,\n",
       " 49652,\n",
       " 21840,\n",
       " 14113,\n",
       " 2973,\n",
       " 48995,\n",
       " 29393,\n",
       " 7240,\n",
       " 45755,\n",
       " 784,\n",
       " 18064,\n",
       " 40990,\n",
       " 46231,\n",
       " 7665,\n",
       " 20110,\n",
       " 32719,\n",
       " 36543,\n",
       " 49707,\n",
       " 38707,\n",
       " 47137,\n",
       " 8009,\n",
       " 17840,\n",
       " 22385,\n",
       " 42241,\n",
       " 24337,\n",
       " 21780,\n",
       " 33928,\n",
       " 32035,\n",
       " 42120]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 50000개 중에서 1퍼센트만 사용\n",
    "num_train = len(trainset_full)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(0.01*num_train)\n",
    "train_idx = indices[:split]\n",
    "train_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x145f9936a50>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainset 가져오기\n",
    "trainset = Subset(trainset_full, train_idx)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# validation 데이터셋\n",
    "# CIFAR-10 검증 데이터셋 로드\n",
    "valset_full = torchvision.datasets.CIFAR10(root='../data', train=False, download=True, transform=transform)\n",
    "\n",
    "# 이중에서 1퍼센트만 사용해보기\n",
    "num_val = len(valset_full)\n",
    "val_indices = list(range(num_val))\n",
    "np.random.shuffle(val_indices) # 랜덤 선택\n",
    "val_split = int(np.floor(0.01 * num_val))  # 예: 전체 데이터셋의 10%만 사용\n",
    "val_idx = val_indices[:val_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val 데이터셋 가져오기\n",
    "valset = Subset(valset_full, val_idx)\n",
    "val_loader = DataLoader(valset, batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# test 데이터셋 가져오기\n",
    "testset_full = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testset = Subset(testset_full, val_idx)\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "vgg16 = VGG16(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수와 옵티마이저 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, train_loader,val_loader, optimizer, criterion, epochs, device):\n",
    "    train_losses = []     # 실제 학습할 때의 loss 값 : 예측값과 실제값의 차이\n",
    "    val_losses = []       # 위에서 학습한 모델을 적용했을 때, val 데이터 셋에 대한 예측값과  실제값의 차이\n",
    "\n",
    "    model.to(device)    # 나중에 실행할 때 GPU/CPU에 있는지 확인\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()   # train 모드로 설정\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device) # data를 GPU로 이동\n",
    "\n",
    "            optimizer.zero_grad()                # 그라디언트 초기화\n",
    "            outputs = model(inputs)             # 예측값\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()                     # 역전파\n",
    "            optimizer.step()                     # 가중치 업데이트\n",
    "            running_loss += loss.item()\n",
    "\n",
    "\n",
    "        # 에포크별 평균 학습 손실 계산\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(epoch_loss)\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}] - Validation loss: {epoch_loss:.3f}')\n",
    "\n",
    "\n",
    "        # 검증 과정\n",
    "        model.eval()                # 평가 모드로 전환\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_val_loss += loss.item()\n",
    "\n",
    "        # 에포크 별 검증 손실 계산\n",
    "        epoch_val_loss = running_val_loss / len(val_loader)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}] - Validation loss: {epoch_loss:.3f}')\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. 모델 학습 (평가 함수는 아래에 정의함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cross_entropy_loss(): argument 'input' (position 1) must be Tensor, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# model, train_loader,val_loader, optimizer, criterion, epochs, device\u001b[39;00m\n\u001b[0;32m      2\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvgg16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[34], line 16\u001b[0m, in \u001b[0;36mtrain_and_validate\u001b[1;34m(model, train_loader, val_loader, optimizer, criterion, epochs, device)\u001b[0m\n\u001b[0;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()                \u001b[38;5;66;03m# 그라디언트 초기화\u001b[39;00m\n\u001b[0;32m     15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)             \u001b[38;5;66;03m# 예측값\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()                     \u001b[38;5;66;03m# 역전파\u001b[39;00m\n\u001b[0;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()                     \u001b[38;5;66;03m# 가중치 업데이트\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MSI\\.conda\\envs\\sesac_gpu_env310_python=3.10\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MSI\\.conda\\envs\\sesac_gpu_env310_python=3.10\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MSI\\.conda\\envs\\sesac_gpu_env310_python=3.10\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MSI\\.conda\\envs\\sesac_gpu_env310_python=3.10\\Lib\\site-packages\\torch\\nn\\functional.py:3059\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3058\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: cross_entropy_loss(): argument 'input' (position 1) must be Tensor, not NoneType"
     ]
    }
   ],
   "source": [
    "# model, train_loader,val_loader, optimizer, criterion, epochs, device\n",
    "device = torch.device(\"cuda\")\n",
    "history = train_and_validate(vgg16, trainloader, val_loader, optimizer, criterion, epochs=10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sesac_gpu_env310_python=3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
