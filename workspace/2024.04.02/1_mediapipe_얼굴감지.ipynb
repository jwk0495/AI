{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq mediapipe --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.기본 얼굴 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# MediaPipe 얼굴 감지 객체와 그리기 객체 초기화\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# 웹캠으로부터 비디오 캡처 시작\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 얼굴 감지 모델 설정\n",
    "with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5) as face_detection:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"웹캠에서 이미지를 읽어오는 데 실패했습니다.\")\n",
    "            # 비디오 캡처가 실패한 경우, 다음 프레임을 계속 시도합니다.\n",
    "            continue\n",
    "\n",
    "        # BGR 이미지를 RGB로 변환\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # # 성능 향상을 위해 이미지 쓰기 불가능으로 설정\n",
    "        # image.flags.writeable = False\n",
    "        \n",
    "        # 이미지에서 얼굴 감지\n",
    "        results = face_detection.process(image)\n",
    "\n",
    "        # # 이미지를 다시 BGR로 변환하여 그리기 작업 준비\n",
    "        # image.flags.writeable = True\n",
    "        \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # 감지된 얼굴에 대한 정보 처리 및 사각형 그리기\n",
    "        if results.detections:\n",
    "            for detection in results.detections:\n",
    "                mp_drawing.draw_detection(image, detection)\n",
    "\n",
    "        # 결과 이미지 표시\n",
    "        cv2.imshow('Face Detection', image)\n",
    "\n",
    "        # 'q'를 누르면 반복을 종료하고 창을 닫음\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# 모든 자원 해제\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.얼굴 전체 메시 그려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MediaPipe 얼굴 메시 객체와 그리기 객체 초기화\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "# 웹캠으로부터 비디오 캡처 시작\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# with 문으로 작성해보기\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as face_mesh:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            continue\n",
    "\n",
    "        # BGR 이미지를 RGB로 변환\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # 성능 향상을 위해 이미지 쓰기 불가능으로 설정\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # 이미지에서 얼굴 메시 검출\n",
    "        results = face_mesh.process(image)\n",
    "\n",
    "        # 이미지를 다시 BGR로 변환하여 그리기 작업 준비\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # 검출된 얼굴 메시에 대한 정보 처리\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                # 전체 얼굴 랜드마크 그리기\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=image,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                    landmark_drawing_spec=drawing_spec,\n",
    "                    connection_drawing_spec=drawing_spec)\n",
    "                \n",
    "                # 특정 부위별로 랜드마크 그리기 (예: 눈, 입, 눈썹)\n",
    "                # 여기서는 전체 얼굴 랜드마크를 그리고 있지만, 필요에 따라 특정 부위만 선택하여 그릴 수 있습니다.\n",
    "                # 예를 들어, 눈의 랜드마크만 그리고 싶다면 눈에 해당하는 랜드마크 인덱스를 사용하여 그리면 됩니다.\n",
    "\n",
    "        # 결과 이미지 표시\n",
    "        cv2.imshow('Face Mesh', image)\n",
    "\n",
    "        # 'q'를 누르면 반복을 종료하고 창을 닫음\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# 모든 자원 해제\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-2. 눈 부위의 랜드 마크 그려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MediaPipe 얼굴 메시(face mesh) 솔루션과 그리기 유틸리티를 초기화\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# 각 눈의 랜드마크 인덱스를 정의\n",
    "LEFT_EYE_INDICES = [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398]\n",
    "RIGHT_EYE_INDICES = [33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246]\n",
    "\n",
    "# 웹캠 시작\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# FaceMesh 모델을 초기화. \n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1, # 최대 얼굴 수\n",
    "    refine_landmarks=True, # 각 부위별 특징을 세밀하게 추출할지 결정\n",
    "    min_detection_confidence=0.5, \n",
    "    min_tracking_confidence=0.5) as face_mesh:\n",
    "    \n",
    "    # 비디오가 열려 있을 경우 프레임 계속 읽어오기\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            continue  # 프레임 읽기 실패 시 다음 프레임으로\n",
    "\n",
    "        # MediaPipe는 RGB이미지 사용 - BGR에서 RGB로색상 변환\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Face Mesh 처리 결과\n",
    "        results = face_mesh.process(image)\n",
    "\n",
    "        # 그리기 작업을 위해 이미지를 다시 BGR로 변환\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # 얼굴 랜드마크가 확인될 경우, \n",
    "        if results.multi_face_landmarks:\n",
    "\n",
    "            # 검출된 각 얼굴에 랜드마크 표시\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "\n",
    "                # 왼쪽 눈을 파란색으로 그리기\n",
    "                for idx in LEFT_EYE_INDICES:\n",
    "                    point = face_landmarks.landmark[idx]\n",
    "                    x = int(point.x * image.shape[1])\n",
    "                    y = int(point.y * image.shape[0])\n",
    "                    cv2.circle(image, (x, y), 1, (255, 0, 0), -1)\n",
    "\n",
    "                # 오른쪽 눈을 녹색으로 그리기\n",
    "                for idx in RIGHT_EYE_INDICES:\n",
    "                    point = face_landmarks.landmark[idx]\n",
    "                    x = int(point.x * image.shape[1])\n",
    "                    y = int(point.y * image.shape[0])\n",
    "                    cv2.circle(image, (x, y), 1, (0, 255, 0), -1)\n",
    "\n",
    "        # 최종 결과 표시\n",
    "        cv2.imshow('Eyes Landmarks', image)\n",
    "\n",
    "        # 'q' 키를 누르면 반복을 종료합니다.\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# 자원을 해제합니다.\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({(7, 163),\n",
       "           (33, 7),\n",
       "           (33, 246),\n",
       "           (144, 145),\n",
       "           (145, 153),\n",
       "           (153, 154),\n",
       "           (154, 155),\n",
       "           (155, 133),\n",
       "           (157, 173),\n",
       "           (158, 157),\n",
       "           (159, 158),\n",
       "           (160, 159),\n",
       "           (161, 160),\n",
       "           (163, 144),\n",
       "           (173, 133),\n",
       "           (246, 161)})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_face_mesh.FACEMESH_RIGHT_EYE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-2. 눈 부위의 랜드 마크 그려보기2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MediaPipe Face Mesh 모듈과 그리기 모듈 초기화\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# 웹캠 설정\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as face_mesh:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            continue\n",
    "\n",
    "        # BGR 이미지를 RGB로 변환\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # Face Mesh 처리\n",
    "        results = face_mesh.process(image_rgb)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                # 왼쪽 눈 랜드마크 그리기\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=image,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_LEFT_EYE,  # 오른쪽 눈 랜드마크 연결\n",
    "                    landmark_drawing_spec=None,  # 랜드마크 스타일 지정 (None이면 기본값 사용)\n",
    "                    connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1)  # 연결선 스타일 지정\n",
    "                )\n",
    "                # 오른쪽 눈 랜드마크 그리기\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=image,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_RIGHT_EYE,  # 오른쪽 눈 랜드마크 연결\n",
    "                    landmark_drawing_spec=None,  # 랜드마크 스타일 지정 (None이면 기본값 사용)\n",
    "                    connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1)  # 연결선 스타일 지정\n",
    "                )\n",
    "\n",
    "        # 결과 이미지 표시\n",
    "        cv2.imshow('Eyes Landmarks', image)\n",
    "\n",
    "        # 'q'를 눌러 종료\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-3. 눈썹 부위의 랜드 마크 그려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MediaPipe 얼굴 메시(face mesh) 솔루션과 그리기 유틸리티를 초기화\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# 왼쪽 눈썹의 상세한 랜드마크 인덱스\n",
    "LEFT_EYEBROW_INDICES = [70, 63, 105, 66, 107, 55, 65, 52, 53, 46, 124, 35, 107, 336]\n",
    "\n",
    "# 오른쪽 눈썹의 상세한 랜드마크 인덱스\n",
    "RIGHT_EYEBROW_INDICES = [300, 293, 334, 296, 336, 285, 295, 282, 283, 276, 353, 265, 340, 285]\n",
    "\n",
    "# 웹캠 시작\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# FaceMesh 모델을 초기화. \n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1, # 최대 얼굴 수\n",
    "    refine_landmarks=True, # 각 부위별 특징을 세밀하게 추출할지 결정\n",
    "    min_detection_confidence=0.5, \n",
    "    min_tracking_confidence=0.5) as face_mesh:\n",
    "    \n",
    "    # 비디오가 열려 있을 경우 프레임 계속 읽어오기\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            continue  # 프레임 읽기 실패 시 다음 프레임으로\n",
    "\n",
    "        # MediaPipe는 RGB이미지 사용 - BGR에서 RGB로색상 변환\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Face Mesh 처리 결과\n",
    "        results = face_mesh.process(image)\n",
    "\n",
    "        # 그리기 작업을 위해 이미지를 다시 BGR로 변환\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # 얼굴 랜드마크가 확인될 경우, \n",
    "        if results.multi_face_landmarks:\n",
    "\n",
    "            # 검출된 각 얼굴에 랜드마크 표시\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "\n",
    "                # 왼쪽 눈썹을 파란색으로 그리기\n",
    "                for idx in LEFT_EYEBROW_INDICES:\n",
    "                    point = face_landmarks.landmark[idx]\n",
    "                    x = int(point.x * image.shape[1])\n",
    "                    y = int(point.y * image.shape[0])\n",
    "                    cv2.circle(image, (x, y), 1, (255, 0, 0), -1)\n",
    "\n",
    "                # 오른쪽 눈썹을 녹색으로 그리기\n",
    "                for idx in RIGHT_EYEBROW_INDICES:\n",
    "                    point = face_landmarks.landmark[idx]\n",
    "                    x = int(point.x * image.shape[1])\n",
    "                    y = int(point.y * image.shape[0])\n",
    "                    cv2.circle(image, (x, y), 1, (0, 255, 0), -1)\n",
    "\n",
    "        # 최종 결과 표시\n",
    "        cv2.imshow('Eye Brows', image)\n",
    "\n",
    "        # 'q' 키를 누르면 반복을 종료합니다.\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# 자원을 해제합니다.\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-3. 눈썹 부위의 랜드 마크 그려보기2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MediaPipe Face Mesh 모듈과 그리기 모듈 초기화\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# 웹캠 설정\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as face_mesh:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            continue\n",
    "\n",
    "        # BGR 이미지를 RGB로 변환\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # Face Mesh 처리\n",
    "        results = face_mesh.process(image_rgb)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                # 왼쪽 눈썹 랜드마크 그리기\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=image,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_LEFT_EYEBROW, # 왼쪽 눈썹 랜드마크 연결\n",
    "                    landmark_drawing_spec=None,  # 랜드마크 스타일 지정 (None이면 기본값 사용)\n",
    "                    connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1)  # 연결선 스타일 지정\n",
    "                )\n",
    "                # 오른쪽 눈썹 랜드마크 그리기\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=image,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_RIGHT_EYEBROW,  # 오른쪽 눈썹 랜드마크 연결\n",
    "                    landmark_drawing_spec=None,  # 랜드마크 스타일 지정 (None이면 기본값 사용)\n",
    "                    connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1)  # 연결선 스타일 지정\n",
    "                )\n",
    "\n",
    "        # 결과 이미지 표시\n",
    "        cv2.imshow('Eye Brows', image)\n",
    "\n",
    "        # 'q'를 눌러 종료\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-4. 코 부위의 랜드마크 그려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MediaPipe Face Mesh 모듈과 그리기 모듈 초기화\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# 웹캠 설정\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as face_mesh:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            continue\n",
    "\n",
    "        # BGR 이미지를 RGB로 변환\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # Face Mesh 처리\n",
    "        results = face_mesh.process(image_rgb)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                # 코 부위의 랜드마크 그리기\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=image,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_NOSE, \n",
    "                    landmark_drawing_spec=None,  # 랜드마크 스타일 지정 (None이면 기본값 사용)\n",
    "                    connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1)  # 연결선 스타일 지정\n",
    "                )\n",
    "\n",
    "        # 결과 이미지 표시\n",
    "        cv2.imshow('Nose', image)\n",
    "\n",
    "        # 'q'를 눌러 종료\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-5. 입의 랜드 마크 그려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MediaPipe Face Mesh 모듈과 그리기 모듈 초기화\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# 웹캠 설정\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as face_mesh:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            continue\n",
    "\n",
    "        # BGR 이미지를 RGB로 변환\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # Face Mesh 처리\n",
    "        results = face_mesh.process(image_rgb)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                # 코 부위의 랜드마크 그리기\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=image,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_LIPS, \n",
    "                    landmark_drawing_spec=None,  # 랜드마크 스타일 지정 (None이면 기본값 사용)\n",
    "                    connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1)  # 연결선 스타일 지정\n",
    "                )\n",
    "\n",
    "        # 결과 이미지 표시\n",
    "        cv2.imshow('Lips', image)\n",
    "\n",
    "        # 'q'를 눌러 종료\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-6. 얼굴만 인식해서 얼굴만 따오기 - 추가 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MediaPipe 얼굴 메시와 그리기 객체 초기화\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "# 웹캠으로부터 비디오 캡처 시작\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as face_mesh:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            continue\n",
    "\n",
    "        # BGR 이미지를 RGB로 변환\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # 성능 향상을 위해 이미지 쓰기 불가능으로 설정\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # 이미지에서 얼굴 메시 검출\n",
    "        results = face_mesh.process(image)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                # 얼굴 경계 찾기\n",
    "                h, w, _ = image.shape\n",
    "                xmin = w\n",
    "                ymin = h\n",
    "                xmax = ymax = 0\n",
    "                for lm in face_landmarks.landmark:\n",
    "                    x, y = int(lm.x * w), int(lm.y * h)\n",
    "                    if x < xmin:\n",
    "                        xmin = x\n",
    "                    if x > xmax:\n",
    "                        xmax = x\n",
    "                    if y < ymin:\n",
    "                        ymin = y\n",
    "                    if y > ymax:\n",
    "                        ymax = y\n",
    "                \n",
    "                # 얼굴 부위 추출\n",
    "                face_image = image[ymin:ymax, xmin:xmax]\n",
    "                # RGB 이미지를 BGR로 변환하여 표시 준비\n",
    "                face_image_bgr = cv2.cvtColor(face_image, cv2.COLOR_RGB2BGR)\n",
    "                cv2.imshow('Extracted Face', face_image_bgr)\n",
    "\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# 모든 자원 해제\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sesac2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
